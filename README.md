# Linguistic Integrity in Human-AI Collaboration  
### A Code for Accuracy, Attribution, and Citations

---

## Abstract

This document establishes a principled framework for ensuring transparent and trustworthy language in AI-assisted communication, with a focus on quotation ethics, source fidelity, and the responsible use of attribution. Designed for legal, academic, journalistic, and technical contexts, the Code outlines five core rules that distinguish verbatim quotation from paraphrase, prioritize precision over polish, and promote honest uncertainty where appropriate.

By defining clear boundaries for quotation marks, requiring traceable citations, and encouraging explicit content tagging, this Code offers both a philosophical foundation and an actionable guide for preserving linguistic integrity in human-AI collaboration. It is intended as both a practical protocol and a normative standard for anyone relying on AI to generate, interpret, or present language that others may trust.

---

## ğŸ“œ The Five Rules

### **Rule 1: Quotation Marks Require Verbatim Language**

If you put words inside quotation marks, you must include **only exact, verbatim language**.

- No summaries, paraphrases, or cleaned-up wording are permitted inside quotation marks.
- Quotation marks signal that the words appear *exactly* as they do in the source. This rule is non-negotiable.

You may omit source text from a quote **only if all three conditions below are met**:

1. The omitted text is not legally or contextually relevant to the point being made;
2. The omission does not alter the substance, tone, or legal impact of the quote; **AND**
3. You insert ellipses (`...`) precisely where the text is omitted.

> ğŸ”´ *Never silently skip or compress quoted material.*

---

### **Rule 2: Remove Quotation Marks When Paraphrasing**

When paraphrasing or synthesizing:

- **Remove quotation marks entirely.**
- Clearly identify the content as paraphrased.
- Retain **attribution** with a citation traceable to the source.

**Example**:  
> *According to Smith, the court ruled thatâ€¦*

---

### **Rule 3: Precision Outweighs Polish in Legal Contexts**

In legal (or similarly high-stakes) settings:

- It is not only acceptableâ€”but **preferred**â€”to express uncertainty, explain ambiguity, or ask for additional facts.
- Avoid misleading finality in unclear situations.

**Example of appropriate hedging**:  
> *No court appears to have ruled definitively on this issue, but dicta in X v. Y suggestâ€¦*

This approach respects both the **complexity of the law** and the **intelligence of the reader**.

---

### **Rule 4: Rigor Over Gloss**

When in doubt:

- Prioritize **accuracy over neatness**.
- Prioritize **clarity over conclusiveness**.

Transparency signals **respect for the userâ€™s intelligence and agency**.

---

### **Rule 5: Confirm All Quoted Material and Citations**

Before responding to legal or factual questions:

- Double-check all quoted material.
- Use **source retrieval logs** or references to confirm that quoted text matches **the source tokens exactly**.
- Verify that it is **word-for-word** and **accurately cited**.

> ğŸ” *No summaries, no approximations, no inference dressed up as quote.*

**Best Practice**: Cite to **official case reporters** rather than summaries or secondary sources.

---

## ğŸ› ï¸ Implementation Suggestions

To make transparency explicit:

- Tag generated content as `(verbatim)`, `(paraphrased)`, or `(summary)`
- Consider UI elements such as:
  - Colored brackets  
  - Mouseover source previews  
  - Inline citations or tokens clearly identifying quotation status

These mechanisms can help **human and AI collaborators** alike distinguish between types of language with confidence and traceability.

---

## ğŸ“˜ License & Use

This Code is intended as an open and evolving standard. Adaptation for use in legaltech, publishing, education, and AI development is encouraged with attribution.

> **Suggested citation**:  
> *â€œLinguistic Integrity in Human-AI Collaboration: A Code for Accuracy, Attribution, and Citationsâ€ (2025).*
